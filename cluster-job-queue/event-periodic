#!/bin/bash
################################################################################
##
## Alces Clusterware - Handler hook
## Copyright (C) 2017 Stephen F. Norledge and Alces Software Ltd.
##
################################################################################
setup() {
    local a xdg_config
    IFS=: read -a xdg_config <<< "${XDG_CONFIG_HOME:-$HOME/.config}:${XDG_CONFIG_DIRS:-/etc/xdg}"
    for a in "${xdg_config[@]}"; do
        if [ -e "${a}"/clusterware/config.rc ]; then
            source "${a}"/clusterware/config.rc
            break
        fi
    done
    if [ -z "${cw_ROOT}" ]; then
        echo "$0: unable to locate clusterware configuration"
        exit 1
    fi
    kernel_load
}

bucket_path() {
  local relative_path
  relative_path="$1"

  _job_queue_bucket_path "${QUEUE}" "${relative_path}"
}

work_dir_path() {
  local relative_path
  relative_path="$1"

  if [ "${relative_path}" == "" ] ; then
    echo "${WORK_DIR}"/"${QUEUE}"
  else
    echo "${WORK_DIR}"/"${QUEUE}"/"${relative_path}"
  fi
}

validate_job_file() {
  local job_file rejected_dir rejected_file custom_validation_file exit_code errors
  job_file=$1
  rejected_dir=$2
  rejected_file=$3
  custom_validation_file="${WORK_DIR}"/customizer/"${QUEUE}"/share/validate-job

  if [ -f "${custom_validation_file}" ] ; then
    chmod +x "${custom_validation_file}"
    errors=$( "${custom_validation_file}" "${job_file}" "${rejected_dir}" )
    exit_code=$?
    if [ $exit_code -ne 0 ] ; then
        mkdir -p $( dirname "${rejected_file}" )
        echo "${errors}" > "${rejected_file}"
    fi
    return $exit_code
  else
    # Job files are valid by default.
    return 0
  fi
}


execute_job() {
  local job_file status_file output_dir custom_job_runner exit_code
  job_file=$1
  status_file=$2
  output_dir=$3
  custom_job_runner="${WORK_DIR}"/customizer/"${QUEUE}"/share/process-job
  
  if [ -f "${custom_job_runner}" ] ; then
    # If there is a custom job runner, use it to run the job file. 
    chmod +x "${custom_job_runner}"
    "${custom_job_runner}" "${job_file}" "${output_dir}" ${ARGS}
    exit_code=$?
  else
    # If there is not a custom job runner, try executing the job file.
    chmod +x "${job_file}"
    "${job_file}" ${ARGS}
    exit_code=$?
  fi
  echo $exit_code > "${status_file}"
  return $exit_code
}

mark_job_file_as_in_progress() {
  :
}

save_job_output() {
  local output_dir job_id
  job_id=$1
  output_dir=$2

  "${_S3CMD}" sync --quiet \
      $(work_dir_path "${output_dir}"/"${job_id}") \
      $(bucket_path "${output_dir}")/
}

# If there are any objects already stored with job_id, the job is invalid.  We
# don't want to overwrite any previous output.
validate_job_id() {
  local job_id rejected_file existing
  job_id=$1
  rejected_file=$2

  existing=$( "${_S3CMD}" ls \
      $(bucket_path completed/"${job_id}") \
      | wc -l
  )

  if [ $existing -ne 0 ] ; then
    mkdir -p $(dirname $rejected_file)
    echo "Job id ${job_id} previously used" > $rejected_file
    return 1
  fi
}

process_pending_jobs() {
  local job_file job_id exit_code
  local output_dir log_file status_file
  local rejected_dir rejected_file

  echo "$( ls "$(work_dir_path pending)" | wc -l ) pending job(s) found"
  for job_id in $( ls -tr "$(work_dir_path pending)" ) ; do
    echo "Processing job ${job_id}"
    job_file="$(work_dir_path pending/${job_id})"

    output_dir="$(work_dir_path completed/${job_id})"
    log_file="${output_dir}"/logs
    status_file="${output_dir}"/status

    rejected_dir="$(work_dir_path rejected/${job_id})"
    rejected_file="${rejected_dir}"/reason

    mark_job_file_as_in_progress

    echo "Validating job ${job_id}"
    validate_job_id "${job_id}" $rejected_file
    exit_code=$?
    if [ $exit_code -eq 0 ] ; then
      validate_job_file $job_file $rejected_dir $rejected_file
      exit_code=$?
    fi
    if [ $exit_code -ne 0 ] ; then
        echo "Rejected job ${job_id}"
        save_job_output "${job_id}" rejected
        job_queue_delete_job "${QUEUE}" "${job_id}"
    else
        mkdir -p $(dirname $log_file)
        execute_job $job_file $status_file $output_dir >"${log_file}" 2>&1
        exit_code=$?
        if [ $exit_code -ne 0 ] ; then
            echo "Error during execution of ${job_id}"
        else
            echo "Successfully executed job ${job_id}"
        fi
        save_job_output "${job_id}" completed
        job_queue_delete_job "${QUEUE}" "${job_id}"
    fi
  done
}

# Download any custom job handling script for the current queue.
get_job_handling_customizations() {
    local s3_pending_dir local_pending_dir
    s3_pending_dir="${BUCKET}"/customizer/"${QUEUE}"/share/
    local_pending_dir="${WORK_DIR}"/customizer/"${QUEUE}"/share/

    echo "Getting customization scripts for ${QUEUE} (${s3_pending_dir})"
    mkdir -p "${local_pending_dir}"
    "${_S3CMD}" get --recursive --quiet ${s3_pending_dir} ${local_pending_dir}
}

get_pending_jobs() {
    local s3_pending_dir local_pending_dir
    s3_pending_dir="$(bucket_path pending/)"
    local_pending_dir="$(work_dir_path pending/)"

    echo "Getting pending jobs for ${QUEUE}/${cw_CLUSTER_name} (${s3_pending_dir})"
    mkdir -p "${local_pending_dir}"
    "${_S3CMD}" get --recursive --quiet ${s3_pending_dir} ${local_pending_dir}
}

main() {
    local BUCKET WORK_DIR QUEUE ARGS job_queues
    ARGS="$@"
    job_queues=()
    WORK_DIR=$( mktemp -d -p /tmp cluster-job-queue.XXXXXXXXXXXX )

    echo "Getting job queues"
    _job_queue_get_job_queues
    echo "Found ${#job_queues[@]} job queues"
    for QUEUE in ${job_queues[@]}; do
      echo "Processing cluster job queue ${QUEUE}"
      get_job_handling_customizations
      get_pending_jobs
      process_pending_jobs
    done

    rm -rf "${WORK_DIR}"
}

setup
require handler
require network
require files
require ruby

_S3CMD="${cw_ROOT}"/opt/s3cmd/s3cmd
_ALCES="${cw_ROOT}"/bin/alces

files_load_config config config/cluster

handler_add_libdir "${cw_ROOT}"/etc/handlers/cluster-job-queue/share
require job-queue

handler_tee main "$@"
